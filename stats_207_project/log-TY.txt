### CREATE CONDA ENVIRONMENT ###
create new conda environment: conda create -n cost python=3.8
install all dependencies in requirements.txt EXCEPT for torch (install the other dependencies one-by-one)
install torch separately (with cuda): conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

### DOWNLOAD AND PREPROCESS ELECTRICITY DATASET ###
download electricity dataset from https://archive.ics.uci.edu/dataset/321/electricityloaddiagrams20112014
extract and place LD2011_2014.txt file into datasets folder
python electricity.py

### RUN MODEL ON ELECTRICITY DATASET
python train.py electricity forecast_univar --alpha 0.0005 --kernels 1 2 4 8 16 32 64 128 --max-train-length 201 --batch-size 128 --archive forecast_csv_univar --repr-dims 320 --max-threads 8 --eval
->Evaluation result: {'ours': {24: {'norm': {'MSE': 0.2448862231697096, 'MAE': 0.2728870045552742}, 'raw': {'MSE': 143.59239655824857, 'MAE': 6.607944742858416}}, 48: {'norm': {'MSE': 0.29266839514975956, 'MAE': 0.3069471235562016}, 'raw': {'MSE': 171.6101289648924, 'MAE': 7.432708784071729}}, 168: {'norm': {'MSE': 0.40285509321077134, 'MAE': 0.38106722763525336}, 'raw': {'MSE': 236.21961196060067, 'MAE': 9.227523331381173}}, 336: {'norm': {'MSE': 0.5523162916365232, 'MAE': 0.4685564150907984}, 'raw': {'MSE': 323.85823583061097, 'MAE': 11.346069503082939}}, 720: {'norm': {'MSE': 0.8743921832174718, 'MAE': 0.6455890118670486}, 'raw': {'MSE': 512.7118508517774, 'MAE': 15.632904652588163}}}, 'encoder_infer_time': 9.885488510131836, 'lr_train_time': {24: 0.8593316078186035, 48: 0.984980583190918, 168: 1.4933772087097168, 336: 2.2823972702026367, 720: 3.7027769088745117}, 'lr_infer_time': {24: 0.0039463043212890625, 48: 0.008900165557861328, 168: 0.009029150009155273, 336: 0.014002323150634766, 720: 0.03409457206726074}}

### DOWNLOAD WEATHER DATASET ###
download weather dataset from https://github.com/zhouhaoyi/Informer2020 (find link to google drive)
place WTH.csv in datasets folder

### RUN MODEL ON WEATHER DATASET ###
python train.py WTH forecast_univar --alpha 0.0005 --kernels 1 2 4 8 16 32 64 128 --max-train-length 201 --batch-size 128 --archive forecast_csv_univar --repr-dims 320 --max-threads 8 --eval
->warning: C:\Users\timot\anaconda3\envs\cost\lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
->Evaluation result: {'ours': {24: {'norm': {'MSE': 0.09534841577376477, 'MAE': 0.2119128931782617}, 'raw': {'MSE': 4.198480446745455, 'MAE': 1.4061987570657146}}, 48: {'norm': {'MSE': 0.13786637768959842, 'MAE': 0.260905964314062}, 'raw': {'MSE': 6.070675510885799, 'MAE': 1.7313040156518105}}, 168: {'norm': {'MSE': 0.2038201758181604, 'MAE': 0.33094832694378895}, 'raw': {'MSE': 8.974821643099306, 'MAE': 2.1960868862762384}}, 336: {'norm': {'MSE': 0.23057471327909013, 'MAE': 0.3556473022481107}, 'raw': {'MSE': 10.152905228230997, 'MAE': 2.359982851806203}}, 720: {'norm': {'MSE': 0.23801128660424367, 'MAE': 0.36605720196743746}, 'raw': {'MSE': 10.480360135477012, 'MAE': 2.4290602335537876}}}, 'encoder_infer_time': 13.058956861495972, 'lr_train_time': {24: 1.158919334411621, 48: 1.365792989730835, 168: 1.2726519107818604, 336: 3.016019105911255, 720: 5.110997676849365}, 'lr_infer_time': {24: 0.004997730255126953, 48: 0.006000041961669922, 168: 0.008369207382202148, 336: 0.026015758514404297, 720: 0.0519404411315918}}

### DOWNLOAD ELECTRICITY TRANSFORMERS (ETTh1, ETTh2, ETTm1) DATASETS ###
download from https://github.com/zhouhaoyi/ETDataset

### RUN MODEL ON ELECTRICITY TRANSFORMERS (ETTh1, ETTh2, ETTm1) DATASETS ###
python train.py ETTh1 forecast_univar --alpha 0.0005 --kernels 1 2 4 8 16 32 64 128 --max-train-length 201 --batch-size 128 --archive forecast_csv_univar --repr-dims 320 --max-threads 8 --eval
->C:\Users\timot\anaconda3\envs\cost\lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
->Evaluation result: {'ours': {24: {'norm': {'MSE': 0.03747694485898959, 'MAE': 0.14764086469255558}, 'raw': {'MSE': 3.155858028400667, 'MAE': 1.354825051157082}}, 48: {'norm': {'MSE': 0.057512850872085276, 'MAE': 0.18249138364741418}, 'raw': {'MSE': 4.843041342917397, 'MAE': 1.674630525220968}}, 168: {'norm': {'MSE': 0.09647131796242725, 'MAE': 0.23729344881378214}, 'raw': {'MSE': 8.123655388578017, 'MAE': 2.177521176514045}}, 336: {'norm': {'MSE': 0.11285862680720112, 'MAE': 0.2607577265850114}, 'raw': {'MSE': 9.503597639354465, 'MAE': 2.392840903696233}}, 720: {'norm': {'MSE': 0.1734553989909269, 'MAE': 0.33567607506693625}, 'raw': {'MSE': 14.60632973272224, 'MAE': 3.080328439633089}}}, 'encoder_infer_time': 7.029797554016113, 'lr_train_time': {24: 0.5116713047027588, 48: 0.648369550704956, 168: 0.8493776321411133, 336: 1.064762830734253, 720: 1.8164894580841064}, 'lr_infer_time': {24: 0.003907442092895508, 48: 0.003870725631713867, 168: 0.006054401397705078, 336: 0.008094310760498047, 720: 0.014978408813476562}}

python train.py ETTh2 forecast_univar --alpha 0.0005 --kernels 1 2 4 8 16 32 64 128 --max-train-length 201 --batch-size 128 --archive forecast_csv_univar --repr-dims 320 --max-threads 8 --eval
->C:\Users\timot\anaconda3\envs\cost\lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
->Evaluation result: {'ours': {24: {'norm': {'MSE': 0.07648932016360577, 'MAE': 0.20476100903087735}, 'raw': {'MSE': 10.26530362981068, 'MAE': 2.3720987286478135}}, 48: {'norm': {'MSE': 0.11156887596378795, 'MAE': 0.25272745690977216}, 'raw': {'MSE': 14.973180377419673, 'MAE': 2.9277765402027884}}, 168: {'norm': {'MSE': 0.17448496478389527, 'MAE': 0.3286549336291795}, 'raw': {'MSE': 23.416878815520427, 'MAE': 3.8073750138418823}}, 336: {'norm': {'MSE': 0.19612481326576867, 'MAE': 0.3547833649175444}, 'raw': {'MSE': 26.321070015267527, 'MAE': 4.110065540698708}}, 720: {'norm': {'MSE': 0.20045062020634433, 'MAE': 0.36386950287628317}, 'raw': {'MSE': 26.901617949154954, 'MAE': 4.2153258920430146}}}, 'encoder_infer_time': 6.602524995803833, 'lr_train_time': {24: 0.5530049800872803, 48: 0.6095261573791504, 168: 0.8070030212402344, 336: 1.1090071201324463, 720: 1.7239313125610352}, 'lr_infer_time': {24: 0.0019958019256591797, 48: 0.004987478256225586, 168: 0.0069844722747802734, 336: 0.00696253776550293, 720: 0.010994672775268555}}

python train.py ETTm1 forecast_univar --alpha 0.0005 --kernels 1 2 4 8 16 32 64 128 --max-train-length 201 --batch-size 128 --archive forecast_csv_univar --repr-dims 320 --max-threads 8 --eval
->
->Evaluation result: {'ours': {24: {'norm': {'MSE': 0.014037356852966611, 'MAE': 0.08639001676088706}, 'raw': {'MSE': 1.1811675019743655, 'MAE': 0.792458691070065}}, 48: {'norm': {'MSE': 0.024880095720033222, 'MAE': 0.1159930506956565}, 'raw': {'MSE': 2.0935252114861207, 'MAE': 1.0640083738393518}}, 96: {'norm': {'MSE': 0.038023595892657, 'MAE': 0.14542377912614918}, 'raw': {'MSE': 3.19947949770806, 'MAE': 1.3339774875935095}}, 288: {'norm': {'MSE': 0.07414631504094657, 'MAE': 0.20516712636470505}, 'raw': {'MSE': 6.23901047041452, 'MAE': 1.8820053307367668}}, 672: {'norm': {'MSE': 0.11040133351637889, 'MAE': 0.2527791909131603}, 'raw': {'MSE': 9.289673690158779, 'MAE': 2.318752480937414}}}, 'encoder_infer_time': 25.574013233184814, 'lr_train_time': {24: 1.1352276802062988, 48: 1.3189897537231445, 96: 2.953937292098999, 288: 2.636004686355591, 672: 6.85088586807251}, 'lr_infer_time': {24: 0.008623123168945312, 48: 0.009095430374145508, 96: 0.019550323486328125, 288: 0.01736283302307129, 672: 0.03813934326171875}}

### DOWNLOAD AEP DATASET ###
download from https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption?resource=download
change header 'Datetime' -> 'date'

### RUN MODEL ON AEP DATASET ###
python train.py AEPh forecast_univar --alpha 0.0005 --kernels 1 2 4 8 16 32 64 128 --max-train-length 201 --batch-size 128 --archive forecast_csv_univar --repr-dims 320 --max-threads 8 --eval
-->Evaluation result: {'ours': {24: {'norm': {'MSE': 0.10981195672821951, 'MAE': 0.23767557731525504}, 'raw': {'MSE': 725875.5400869774, 'MAE': 611.0698031667303}}, 48: {'norm': {'MSE': 0.16071381119927666, 'MAE': 0.2919529783499849}, 'raw': {'MSE': 1062345.3735754224, 'MAE': 750.6183457383437}}, 96: {'norm': {'MSE': 0.24258528957921519, 'MAE': 0.3677342321330773}, 'raw': {'MSE': 1603529.6415775712, 'MAE': 945.4538282902346}}, 288: {'norm': {'MSE': 0.36537233217329174, 'MAE': 0.46890202410250553}, 'raw': {'MSE': 2415172.680792762, 'MAE': 1205.5587295408643}}, 672: {'norm': {'MSE': 0.43674111007047217, 'MAE': 0.5265074032816527}, 'raw': {'MSE': 2886932.325172192, 'MAE': 1353.6635872103636}}}, 'encoder_infer_time': 44.96089577674866, 'lr_train_time': {24: 4.8767969608306885, 48: 6.034378528594971, 96: 6.510869979858398, 288: 9.561557531356812, 672: 18.50112748146057}, 'lr_infer_time': {24: 0.020999431610107422, 48: 0.030998945236206055, 96: 0.04099893569946289, 288: 0.06991171836853027, 672: 0.17201566696166992}}
